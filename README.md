* Built LLM-powered data pipelines for economics research, focused on turning messy, unstructured text (scans, legal language, long-form filings) into consistent, analysis-ready datasets by pairing LLM extraction with clear schemas, validation checks, and standardized outputs for downstream statistical work.

  * **AI + Zoning:** Used LLMs to process zoning rules at scale to study housing supply constraints, including workflows to surface and digitize historical zoning ordinances from newspaper scans and translate complex regulatory language into structured variables that could be compared across places and time.

  * **Corporate Agreements:** Used LLM-assisted document understanding to extract pricing terms and covenant language from SEC EDGAR credit agreements, mapping heterogeneous contract formats into a common schema and outputting structured JSON designed for downstream analysis, aggregation, and model-ready features.

* Statistical programmer for applied economics research papers, implementing causal inference designs (DiD/DDD, event studies, IV extensions) plus heterogeneity and robustness analysis, with an emphasis on clean, reproducible code and publication-ready outputs.

* Built a coding-agent workflow on top of the Codex SDK to automate common RA tasks (data wrangling, exploratory analysis, repetitive coding), enabling unattended runs and faster iteration from question → cleaned data → preliminary results.
