Requirement: The MDD, as defined in the Model Development Standard, must be sufficiently detailed such that parties unfamiliar with the model can understand its operation, limitations, and key assumptions. The MDD must include the necessary detail to mitigate key person dependency risk, enable proper operation of the model, facilitate independent reviews by knowledgeable parties with minimal assistance, and reduce the risk associated with implementing model changes.

MVR summary:
The report states MRM reviewed the MDD against the standard using the documentation assessment template and additional materials provided via the validation challenge log, and confirmed the MDD meets the standard with a few exceptions to be synchronized. It documents model operation (architecture, data flows, VML interfaces, supported products/analytics), key assumptions and limitations (e.g., deterministic non-base-curve spread; negative mortgage-rate floor), and includes artifacts and examples (sample VML, reports) that show how to operate the model. Validators independently replicated outputs and reconciled code-change implementations, indicating the documentation enabled review with minimal assistance, and change-management evidence (JIRA, UT/SIT, approvals) was included to reduce implementation risk. The report also notes collaborative enhancement of the MDD content during validation via the assessment template process, while acknowledging remaining areas for enhancement such as incomplete benchmarking coverage for the NPL/RPL portfolio, which is recorded as a self-identified finding.

Rationale: MRM’s process explicitly evaluated the MDD against the required elements (comprehensibility, assumptions/limitations, operability, independent reviewability, change-risk reduction) and used the formal documentation assessment template plus challenge-log follow-ups to enhance and confirm sufficiency. Evidence of independent replication and reconciliations shows the MDD enabled knowledgeable reviewers to assess the model with minimal assistance, and the included operational/change artifacts mitigate key-person dependency and change risk. Although the report flags residual enhancements (e.g., NPL/RPL benchmarking coverage), these are captured within the validation and do not indicate a process gap. 




----



Requirement: The Model Validator must assess both the historical data used to train the model (i.e., model development data) and the operational input data used to run the model.

MVR: The MVR states VN is an integrator/financial calculator not trained on historical data; there is no model-development dataset for VN, and training/estimation data for upstream component models are covered in separate validations. It also notes the VN UI supports both acceptance and production sources with identical input-pull processes. For operational inputs, the MVR describes sources and enterprise controls and addresses all four feeds: IRAP (retired as a model/SDC; SOX/EDQ controls summarized; responsibility for market-data appropriateness now lies with upstream models and downstream consumers), MDR (benchmark MBS portfolios for impact/vetting), Intex (CMO deal data/analytics), and MFCW (EDM outputs consumed by VN’s MF prepayment component, using fields such as effective gross income, rent/value index, unemployment, cap rate, investor spread, expense ratio). The MVR explicitly records that the model owner did not provide a data-quality analysis for MFCW. In addition, the validator performed hands-on VML data-quality tests at the VN interface across assets, debt, and derivatives (removing/emptying “mandatory” fields and observing exception behavior), noting cases where exceptions were not thrown and error messages lacked root-cause clarity. The MVR does not present feed-level empirical testing of MFCW by the validator.

Rationale: The validator properly concluded that “historical training data” are not applicable to this integrator and pointed to component-model reviews, satisfying that half of the requirement. For operational inputs, the process documented sources/controls and executed empirical DQ testing at the VN VML interface, evidencing assessment of inputs VN processes. However, the MVR itself highlights two evidence gaps: (1) no owner-provided DQ analysis for MFCW and no validator-run, feed-level tests shown for that source; and (2) while IRAP responsibility shifts are described, the MVR does not detail how data-quality assurance will be evaluated under the new arrangement. 


--

Requirement: The objective of MRM's independent assessment is to evaluate the data's relevance to the intended model usages, the impact of any data limitations, data quality and controls, and whether appropriate data governance is in place. The Model Validator must assess the modeling data (internal, external, proxy) using the same standards of relevance and reliability. At a minimum: appropriateness/relevance, sufficiency, data-quality controls on immediate upstream models/sources, appropriateness of data transformations and treatments, and reasonableness of descriptive statistics/outliers.

MVR Summary:.
The MVR treats VN as an integrator (no development/training dataset; component-model data are reviewed separately) and identifies the operational input sources IRAP-AWS, MDAR, Intex-AWS, and MFCW, noting the model owner’s statement that VN relies on the appropriateness and quality of upstream sources. VN does not source external data directly; enterprise feeds (IRAP/Intex) handle sourcing and processing, and there were no significant usage changes in this release. It explains that VN does not source external data directly; enterprise feeds (IRAP/Intex) handle sourcing, and no significant changes in VN’s use of those data occurred in this release. For IRAP, the report notes its retirement as a model/SDC, points to a SOX daily curve review, and states that upstream models and downstream consumers now own appropriateness/quality for IRAP data they pass into VN. For MFCW, the MVR explicitly records that the model owner did not provide a data quality analysis, and it shows no validator-performed data quality analysis of that feed. Across its data section, the MVR says MRM assessed appropriateness/relevance of chosen sources and considered reliability, sufficiency, completeness/coverage at the level appropriate for an integrator. In addition, the validators ran VNML interface data-quality tests by removing/emptying mandatory fields across assets, debt, and derivatives, observed exception behavior, documented deficiencies, and issued a finding with recommendations; the report also states VN does not perform data transformations or sampling and relies on upstream providers for any proxy handling. 

Rationale: Process-wise, the validation addresses the standard’s objectives by evaluating relevance and governance of the modeling data that feed VN, recording the IRAP control context and post-retirement responsibility handoff, and providing direct evidence of VNML interface data-quality testing and findings. Items not applicable at the integrator layer (no VN development dataset; no transformations/sampling within VN) are stated as such and handled via separate component-model validations and enterprise controls. While the MVR calls out a clear MFCW data quality analysis gap (owner-provided) and shows no validator analysis of that feed, the gap is explicitly captured; overall, the validator’s documented work meets the minimum required assessments without going beyond what the standard requires for an integrator, so the process Meets Expectations.



-----
-----


Requirement: The Model Validator must also confirm the evidence provided by the Model Owner that model data was sourced from approved sources in adherence with the Enterprise Data Standard and that the group(s) responsible for the data completeness and accuracy are identified and documented. Additionally, for the model production data, the Model Validator is responsible for performing an independent assessment of the production data used within the Test environment, including evaluation of their reliability, relevance, and consistency with the development data. Note, MRM is not responsible for the quality of production data used within the Production environment.

MVR summary (paraphrased).
The MVR confirms that VN’s inputs come from enterprise-approved internal repositories and a recognized external vendor governed by Enterprise Data Governance and Enterprise Data Quality controls, and it identifies the accountable groups and review steps that ensure completeness and accuracy. It notes a narrow gap where one upstream feed did not include a provided data-quality analysis and records that a previously covered internal repository was retired from MRM scope, with appropriateness checks now performed by upstream owners and VN users. For independent assessment of production data in the Test/acceptance environment, the validator ran VML request/response data-quality checks across representative assets, debt, and derivatives (including missing/empty-field cases), performed cross-system comparisons to check consistency, and—where direct runs were not feasible—conducted a limited code review of the input-validation logic (e.g., futures ticker validation) to confirm implemented data checks. The validator also verified that Test and Production use the same ingestion pipeline. Because VN is an integrator and not trained on datasets, the report states there is no separate development dataset; the development-versus-production comparison is therefore not applicable, and reliability/relevance were evaluated on production-sourced samples used in Test. The MVR reiterates that MRM is not responsible for Production-environment data quality.

Rationale — Meets Expectations.
The report documents that the validator confirmed sourcing from approved, enterprise-governed feeds and identified the responsible groups and control steps, satisfying the confirmation and identification elements. It also shows an independent assessment of production data used in Test by executing VML-based checks, reconciling across systems, performing a limited code review where runs were not possible, and verifying identical ingestion—actions that collectively evaluate reliability and relevance in that environment. The “consistency with development data” element is explicitly treated as not applicable for an integrator with no development dataset and is explained in the MVR. On balance, the documented process meets expectations.



---


Requirement: The Model Validator must consider model interconnectivity, as defined in the Model Development Standard, and the corresponding compounding effects during the validation process and evaluate the associated risk. The evaluation of associated risk must consider the risktier of the interconnected models. The intensity of focus and level of effort applied in validating interconnected models is subject to the Model Validator's judgement given the interconnectivity risk.

MVR summary:
The MVR maps VN’s interconnectivity by describing direct upstream feeds and downstream consumers, registered interfaces, and data flows, and it explains compounding effects (e.g., a near-flat portfolio duration where small analytic errors can materially affect enterprise metrics and limits). The validator evaluates associated risk with explicit consideration of the integrator’s High risk tier and the risk tiers of interconnected component models and usages. It assesses the level of impact of direct dependencies on VN’s outputs and performs targeted impact testing on a cross-model assumption to gauge downstream effects, while recommending hygiene actions to keep dependency registrations current. For this High-tier integrator, the report indicates that key dependencies required for VN’s usages were reviewed, and that at least one upstream and one downstream layer is covered for lower-tier items, with depth of testing aligned to interconnectivity risk. Scope and effort are justified: full-scope on the integrator, implementation checks on changed elements, reliance on existing validations for unchanged components, and focused interconnectivity tests where sensitivity is highest, consistent with the Model Validation Standard’s interconnectivity assessment intent.

Rationale — Meets Expectations.
The MVR shows the validator considered interconnectivity and compounding effects, evaluated the associated risk, and anchored that evaluation in the risk tiers of VN and its interconnected models. It addresses the procedure’s emphasis on the level of impact from direct upstream and downstream models, documents a review of key dependencies appropriate to a High-tier model, and indicates at least one-layer coverage for lower-tier linkages. The intensity and level of effort are explained as risk-based judgement—deeper work where interconnectivity risk is concentrated and reliance on prior component reviews elsewhere—which satisfies the standard’s expectation. On this basis, the documented process meets expectations.








