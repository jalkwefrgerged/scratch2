Requirement: The MDD, as defined in the Model Development Standard, must be sufficiently detailed such that parties unfamiliar with the model can understand its operation, limitations, and key assumptions. The MDD must include the necessary detail to mitigate key person dependency risk, enable proper operation of the model, facilitate independent reviews by knowledgeable parties with minimal assistance, and reduce the risk associated with implementing model changes.

MVR summary:
The report states MRM reviewed the MDD against the standard using the documentation assessment template and additional materials provided via the validation challenge log, and confirmed the MDD meets the standard with a few exceptions to be synchronized. It documents model operation (architecture, data flows, VML interfaces, supported products/analytics), key assumptions and limitations (e.g., deterministic non-base-curve spread; negative mortgage-rate floor), and includes artifacts and examples (sample VML, reports) that show how to operate the model. Validators independently replicated outputs and reconciled code-change implementations, indicating the documentation enabled review with minimal assistance, and change-management evidence (JIRA, UT/SIT, approvals) was included to reduce implementation risk. The report also notes collaborative enhancement of the MDD content during validation via the assessment template process, while acknowledging remaining areas for enhancement such as incomplete benchmarking coverage for the NPL/RPL portfolio, which is recorded as a self-identified finding.

Rationale: MRM’s process explicitly evaluated the MDD against the required elements (comprehensibility, assumptions/limitations, operability, independent reviewability, change-risk reduction) and used the formal documentation assessment template plus challenge-log follow-ups to enhance and confirm sufficiency. Evidence of independent replication and reconciliations shows the MDD enabled knowledgeable reviewers to assess the model with minimal assistance, and the included operational/change artifacts mitigate key-person dependency and change risk. Although the report flags residual enhancements (e.g., NPL/RPL benchmarking coverage), these are captured within the validation and do not indicate a process gap. 




----



Requirement: The Model Validator must assess both the historical data used to train the model (i.e., model development data) and the operational input data used to run the model.

MVR: The MVR states VN is an integrator/financial calculator not trained on historical data; there is no model-development dataset for VN, and training/estimation data for upstream component models are covered in separate validations. It also notes the VN UI supports both acceptance and production sources with identical input-pull processes. For operational inputs, the MVR describes sources and enterprise controls and addresses all four feeds: IRAP (retired as a model/SDC; SOX/EDQ controls summarized; responsibility for market-data appropriateness now lies with upstream models and downstream consumers), MDR (benchmark MBS portfolios for impact/vetting), Intex (CMO deal data/analytics), and MFCW (EDM outputs consumed by VN’s MF prepayment component, using fields such as effective gross income, rent/value index, unemployment, cap rate, investor spread, expense ratio). The MVR explicitly records that the model owner did not provide a data-quality analysis for MFCW. In addition, the validator performed hands-on VML data-quality tests at the VN interface across assets, debt, and derivatives (removing/emptying “mandatory” fields and observing exception behavior), noting cases where exceptions were not thrown and error messages lacked root-cause clarity. The MVR does not present feed-level empirical testing of MFCW by the validator.

Rationale: The validator properly concluded that “historical training data” are not applicable to this integrator and pointed to component-model reviews, satisfying that half of the requirement. For operational inputs, the process documented sources/controls and executed empirical DQ testing at the VN VML interface, evidencing assessment of inputs VN processes. However, the MVR itself highlights two evidence gaps: (1) no owner-provided DQ analysis for MFCW and no validator-run, feed-level tests shown for that source; and (2) while IRAP responsibility shifts are described, the MVR does not detail how data-quality assurance will be evaluated under the new arrangement. 

